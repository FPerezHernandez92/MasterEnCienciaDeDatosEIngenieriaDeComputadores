##Modelo lineal para Dobules
fitDoubles=lm(Salary~Doubles)
#fitDoubles
##Modelo lineal para HomeRuns
fitHomeRuns=lm(Salary~HomeRuns)
#fitHomeRuns
##Modelo lineal para Runs_batted_in
fitRunsBattedIn=lm(Salary~Runs_batted_in)
#fitRunsBattedIn
##Creo la matriz para obtener el r cuadrado ajustado
mat_r_squ <- matrix(c(summary(fitRuns)$adj.r.squared,
summary(fitHits)$adj.r.squared,
summary(fitDoubles)$adj.r.squared,
summary(fitHomeRuns)$adj.r.squared,
summary(fitRunsBattedIn)$adj.r.squared))
rownames(mat_r_squ) <- c("fitRuns","fitHits","fitDoubles",
"fitHomeRuns","fitRunsBattedIn")
colnames(mat_r_squ) <- c("adj.r.squared")
##Creo la matriz para obtener el p valor
mat_p_val <- matrix(c(summary(fitRuns)$coefficients["Runs","Pr(>|t|)"],
summary(fitHits)$coefficients["Hits","Pr(>|t|)"],
summary(fitDoubles)$coefficients["Doubles","Pr(>|t|)"],
summary(fitHomeRuns)$coefficients["HomeRuns","Pr(>|t|)"],
summary(fitRunsBattedIn)$coefficients["Runs_batted_in","Pr(>|t|)"]))
colnames(mat_p_val) <- c("p-value")
regresion_simple <- cbind(mat_r_squ,mat_p_val)
##Creo la matriz para obtener el rmse
mat_rmse <- matrix(c(sqrt(sum(fitRuns$residuals^2)/(length(fitRuns$residuals)-2)),
sqrt(sum(fitHits$residuals^2)/(length(fitHits$residuals)-2)),
sqrt(sum(fitDoubles$residuals^2)/(length(fitDoubles$residuals)-2)),
sqrt(sum(fitHomeRuns$residuals^2)/(length(fitHomeRuns$residuals)-2)),
sqrt(sum(fitRunsBattedIn$residuals^2)/(length(fitRunsBattedIn$residuals)-2))))
colnames(mat_rmse) <- c("RMSE")
##Uno los matrices y la muestro
regresion_simple <- cbind(regresion_simple,mat_rmse)
regresion_simple
##Creo las gráficas de los modelos realizados
par(mfrow=c(3,2))
plot(Runs,Salary)
abline(fitRuns,col="red")
#confint(fitRuns)
plot(Hits,Salary)
abline(fitHits,col="green")
#confint(fitHits)
plot(Doubles,Salary)
abline(fitDoubles,col="blue")
#confint(fitDoubles)
plot(HomeRuns,Salary)
abline(fitHomeRuns,col="orange")
#confint(fitHomeRuns)
plot(Runs_batted_in,Salary)
abline(fitRunsBattedIn,col="brown")
#confint(fitRunsBattedIn)
par(mfrow=c(1,1))
##Como la siguiente parte es realizar los modelos de
##regresión múltiple, voy a realizar las funciones que se vieron
##para realizar cross-validation pero modificadas para obtener los
##datos de una manera más clara
##Función para realizar cross-validation de los modelos lm
run_lm_fold <- function(i, x,modelo, tt = "test") {
file <- paste(x, "-5-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@")
file <- paste(x, "-5-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@")
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
if (tt == "train") {
test <- x_tra
}
else {
test <- x_tst
}
fitMulti=lm(modelo,x_tra)
yprime=predict(fitMulti,test)
mse <- sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
resumen <- summary(fitMulti)
#Error estandar residual
a <- 100*(resumen$sigma/(mean(x_tra$Y)))
a <- format(a,digits=3)
#Coeficiente de determinacion R2
b <- resumen$r.squared
b <- format(b,digits=3)
#Coeficiente de determinacion R2 ajustado
c <- resumen$adj.r.squared
c <- format(c,digits=3)
#RMSE
d <- sqrt(sum(fitMulti$residuals^2)/(length(fitMulti$residuals)-2))
d <- format(d,digits = 3)
salida <- list("EER" = a, "R2" = b, "R2_Adj" = c, "MSE" = mse, "RMSE" = d)
return (salida)
}
##Función para realizar el análisis de cross-validation
Analisis_lm_fold <- function(modelo, nombre){
lmMSEtrain<-(sapply(1:5,run_lm_fold,nombre,modelo,"train"))
lmMSEtest<-(sapply(1:5,run_lm_fold,nombre,modelo,"test"))
#Error Estandar Residual
a <- mean(as.numeric(lmMSEtest[1,]))
at <- ifelse(a<10,"Si","No")
a <- format(a,digits=3)
# Coeficiente de determinacion R2
b <- mean(as.numeric(lmMSEtest[2,]))
bt <- ifelse(b>0.8,"Si", "No")
# Coeficiente de determinacion R2 ajustado
c <- mean(as.numeric(lmMSEtest[3,]))
ct <- ifelse(abs(b-c)<0.01,"Si","No")
b <- format(b,digits = 3)
c <- format(c,digits = 3)
d <- mean(as.numeric(lmMSEtest[5,]))
salida <- list ( "EER"     = a, "T1" = at,
"R2"      = b, "T2" = bt,
"R2_Adj"  = c, "T3" = ct,
"MSEtrain" = mean(as.numeric(lmMSEtrain[4,])),
"MSEtest" = mean(as.numeric(lmMSEtest[4,])),
"RMSE" = d)
return (salida)
}
nombre <- "baseball/baseball"
#Número de las variables:Runs 3, Hits 4, Doubles 5, HomeRuns 7, Runs_batted_in 8
modelo1 <- Y~X3
modelo2 <- Y~X4
modelo3 <- Y~X5
modelo4 <- Y~X7
modelo5 <- Y~X8
modelo6 <- Y~.
lm1 <- Analisis_lm_fold(modelo1,nombre)
lm2 <- Analisis_lm_fold(modelo2,nombre)
lm3 <- Analisis_lm_fold(modelo3,nombre)
lm4 <- Analisis_lm_fold(modelo4,nombre)
lm5 <- Analisis_lm_fold(modelo5,nombre)
lm6 <- Analisis_lm_fold(modelo6,nombre)
df <- data.frame(rbind(model1=lm1,model2=lm2,model3=lm3,model4=lm4,model5=lm5,model6=lm6))
df
##Podemos ver como de momento el mejor modelo sería el modelo6, con todas las variables,
##ya que obtenemos un R2 ajustado de 0,68, muy superior al resto. Además el MSE de test medio
##es el más bajo de todos los modelos. Pero para los modelos simples, tenemos que el que mejor
##R2 ajustado sería el modelo5, el cual tiene también el MSEtest más pequeño.
regresion_simple_dv
regresion_simple_cv <- data.frame(rbind(model1=lm1,model2=lm2,model3=lm3,model4=lm4,model5=lm5,model6=lm6))
regresion_simple_cv
###############################################################
################### REGRESIÓN MÚLTIPLE ########################
###############################################################
##Vamos a pasar ahora a buscar el mejor modelo de regresión múltiple
fitM1=lm(Salary~.,data=baseball)
summary(fitM1) #R2adj 0.686
##Voy a quitar algunas de las que parece que tienen menos influencia como:
##Doubles, Hits, Triples
fitM2=lm(Salary~. -Doubles-Hits-Triples,data=baseball)
summary(fitM2) #R2adj 0.688 hemos mejorado
modelo7 <- Y~. -X4-X5-X6
lm7 <- Analisis_lm_fold(modelo7,nombre)
#lm7
##Sigo quitando, por ejemplo: Runs, Batting_average
fitM3=lm(Salary~. -Doubles-Hits-Triples-Runs-Batting_average,data=baseball)
summary(fitM3) #R2adj 0.6881
modelo8 <- Y~. -X4-X5-X6-X3-X1
lm8 <- Analisis_lm_fold(modelo8,nombre)
#lm8
##Pruebo a quitar: `On-base_percentage`
fitM4=lm(Salary~. -Doubles-Hits-Triples-Runs-Batting_average-`On-base_percentage`,data=baseball)
summary(fitM4) #R2adj 0.688
modelo9 <- Y~. -X4-X5-X6-X3-X1-X2
lm9 <- Analisis_lm_fold(modelo9,nombre)
#lm9
##Pruebo a quitar: Errors
fitM5=lm(Salary~. -Doubles-Hits-Triples-Runs-Batting_average-`On-base_percentage`-Errors,data=baseball)
summary(fitM5) #R2adj 0.6876
modelo10 <- Y~. -X4-X5-X6-X3-X1-X2-X12
lm10 <- Analisis_lm_fold(modelo10,nombre)
#lm10
##Pruebo a quitar: Walks y Arbitration
fitM6=lm(Salary~. -Doubles-Hits-Triples-Runs-Batting_average-`On-base_percentage`-Errors-Walks-Arbitration,data=baseball)
summary(fitM6) #R2adj 0.685
modelo11 <- Y~. -X4-X5-X6-X3-X1-X2-X12-X9-X16
lm11 <- Analisis_lm_fold(modelo11,nombre)
#lm11
##Llegados a este punto las variables que nos quedan que parecen más relevantes son:
##X7:HomeRuns , X8:Runs_batted_in ,X10:`Strike-Outs` ,X11:Stolen_bases ,
##X13:Free_agency_eligibility ,X14:Free_agent ,X15:Arbitration_eligibility
fitM7=lm(Salary~HomeRuns*Runs_batted_in*`Strike-Outs`*Stolen_bases*Free_agency_eligibility*Free_agent*Arbitration_eligibility,data=baseball)
summary(fitM7) #R2adj 0.7932 el mejor hasta el momento
modelo12 <- Y~X7*X8*X10*X11*X13*X14*X15
lm12 <- Analisis_lm_fold(modelo12,nombre)
#lm12
##Las variables que interfieren (cuando p-value es pequeño) son: Free_agent, Runs_batted_in,
##Free_agency_eligibility, Stolen_bases, `Strike-Outs`,HomeRuns
##Por lo que voy a probar a eliminar la variable Arbitration_eligibility
fitM8=lm(Salary~HomeRuns*Runs_batted_in*`Strike-Outs`*Stolen_bases*Free_agency_eligibility*Free_agent,data=baseball)
summary(fitM8) #R2adj 0.7195
modelo13 <- Y~X7*X8*X10*X11*X13*X14
lm13 <- Analisis_lm_fold(modelo13,nombre)
#lm13
#Sigo probando modelos
fitM9=lm(Salary~(HomeRuns^2)*(Runs_batted_in^2)*(`Strike-Outs`^2)*Stolen_bases*Free_agency_eligibility*Free_agent*Arbitration_eligibility,data=baseball)
summary(fitM9) #R2adj 0.7932 igual que el mejor
modelo14 <- Y~(X7^2)*(X8^2)*(X10^2)*X11*X13*X14*X15
lm14 <- Analisis_lm_fold(modelo14,nombre)
#lm14
fitM10=lm(Salary~(HomeRuns^2)*(Runs_batted_in^2)*(`Strike-Outs`^2)*(Stolen_bases^2)*(Free_agency_eligibility^2)*(Free_agent^2)*(Arbitration_eligibility^2),data=baseball)
summary(fitM10) #R2adj 0.7932 igual que el mejor
modelo15 <- Y~(X7^2)*(X8^2)*(X10^2)*(X11^2)*(X13^2)*(X14^2)*(X15^2)
lm15 <- Analisis_lm_fold(modelo15,nombre)
#lm15
fitM11=lm(Salary~I(HomeRuns^2)*I(Runs_batted_in^2)*I(`Strike-Outs`^2)*(Stolen_bases^2)*(Free_agency_eligibility^2)*(Free_agent^2)*(Arbitration_eligibility^2),data=baseball)
summary(fitM11) #R2adj 0.7885
modelo16 <- Y~I(X7^2)*I(X8^2)*I(X10^2)*(X11^2)*(X13^2)*(X14^2)*(X15^2)
lm16 <- Analisis_lm_fold(modelo16,nombre)
#lm16
fitM12=lm(Salary~I(HomeRuns^2)*I(Runs_batted_in^2)*I(`Strike-Outs`^2)*I(Stolen_bases^2)*I(Free_agency_eligibility^2)*I(Free_agent^2)*I(Arbitration_eligibility^2),data=baseball)
summary(fitM12) #R2adj 0.7854
modelo17 <- Y~I(X7^2)*I(X8^2)*I(X10^2)*I(X11^2)*I(X13^2)*I(X14^2)*I(X15^2)
lm17 <- Analisis_lm_fold(modelo17,nombre)
#lm17
fitM13=lm(Salary~I(HomeRuns^2)+I(Runs_batted_in^2)+I(`Strike-Outs`^2)+I(Stolen_bases^2)+I(Free_agency_eligibility^2)+I(Free_agent^2)+I(Arbitration_eligibility^2),data=baseball)
summary(fitM13) #R2adj 0.6914
modelo18 <- Y~I(X7^2)+I(X8^2)+I(X10^2)+I(X11^2)+I(X13^2)+I(X14^2)+(X15^2)
lm18 <- Analisis_lm_fold(modelo18,nombre)
#lm18
##X7:HomeRuns , X8:Runs_batted_in ,X10:`Strike-Outs` ,X11:Stolen_bases ,
##X13:Free_agency_eligibility ,X14:Free_agent ,X15:Arbitration_eligibility
fitM14=lm(Salary~I(Runs_batted_in*HomeRuns^2)+I(`Strike-Outs`*Stolen_bases^2)+I(Free_agency_eligibility*Free_agent^2)+I(Arbitration_eligibility^2),data=baseball)
summary(fitM14) #R2adj 0.3087
modelo19 <- Y~I(X8*X7^2)+I(X10*X11^2)+I(X13*X14^2)+I(X15^2)
lm19 <- Analisis_lm_fold(modelo19,nombre)
#lm19
fitM15=lm(Salary~I(Runs_batted_in*Free_agency_eligibility^2)+I(Runs_batted_in*Arbitration_eligibility^2)+I(Stolen_bases*Free_agency_eligibility^2)+I(Stolen_bases*Arbitration_eligibility^2)+I(HomeRuns*`Strike-Outs`*Free_agent^2),data=baseball)
summary(fitM15) #R2adj 0.7363
modelo20 <- Y~I(X8*X13^2)+I(X8*X15^2)+I(X11*X13^2)+I(X11*X15^2)+I(X7*X10*X14^2)
lm20 <- Analisis_lm_fold(modelo20,nombre)
#lm20
fitM16=lm(Salary~I(Runs_batted_in*Free_agency_eligibility^2)+I(Runs_batted_in*Arbitration_eligibility^2)+I(Stolen_bases*Free_agency_eligibility^2)+I(Stolen_bases*Arbitration_eligibility^2),data=baseball)
summary(fitM16) #R2adj 0.7363
modelo21 <- Y~I(X8*X13^2)+I(X8*X15^2)+I(X11*X13^2)+I(X11*X15^2)
lm21 <- Analisis_lm_fold(modelo21,nombre)
#lm21
fitM17=lm(Salary~I(Runs_batted_in*Free_agency_eligibility^2)+I(Runs_batted_in*Arbitration_eligibility^2)+I(Stolen_bases*Free_agency_eligibility^2),data=baseball)
summary(fitM17) #R2adj 0.7303
modelo22 <- Y~I(X8*X13^2)+I(X8*X15^2)+I(X11*X13^2)
lm22 <- Analisis_lm_fold(modelo22,nombre)
#lm22
fitM18=lm(Salary~I(Runs_batted_in^2)*Free_agency_eligibility+(`Strike-Outs`+Stolen_bases)*Free_agency_eligibility+I((Runs_batted_in+Stolen_bases)^3)*Arbitration_eligibility,data=baseball)
summary(fitM18) #R2adj 0.7479
modelo23 <- Y~I(X8^2)*X13+(X10+X11)*X13+I((X8+X11)^3)*X15
lm23 <- Analisis_lm_fold(modelo23,nombre)
#lm23
fitM19=lm(Salary~I(Runs_batted_in^2)*Free_agency_eligibility+(`Strike-Outs`+Stolen_bases)*Free_agency_eligibility+I((Runs_batted_in+Stolen_bases)^3)*Arbitration_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Free_agency_eligibility,data=baseball)
summary(fitM19) #R2adj 0.7549
modelo24 <- Y~I(X8^2)*X13+(X10+X11)*X13+I((X8+X11)^3)*X15+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X13
lm24 <- Analisis_lm_fold(modelo24,nombre)
#lm24
fitM20=lm(Salary~I(Runs_batted_in^2)*Free_agency_eligibility+(`Strike-Outs`+Stolen_bases)*Free_agency_eligibility+I((Runs_batted_in+Stolen_bases)^3)*Arbitration_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Free_agency_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Arbitration_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Free_agent,data=baseball)
summary(fitM20) #R2adj 0.7704
modelo25 <- Y~I(X8^2)*X13+(X10+X11)*X13+I((X8+X11)^3)*X15+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X13+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X15+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X14
lm25 <- Analisis_lm_fold(modelo25,nombre)
#lm25
fitM21=lm(Salary~I(Runs_batted_in^2)*Free_agency_eligibility+(`Strike-Outs`+Stolen_bases)*Free_agency_eligibility+I((Runs_batted_in+Stolen_bases)^3)*Arbitration_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Free_agency_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Arbitration_eligibility+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Free_agent+
(Batting_average+`On-base_percentage`+Runs+Hits+Doubles+Triples+HomeRuns+Walks+Errors)*Arbitration,data=baseball)
summary(fitM21) #R2adj 0.7795
modelo26 <- Y~I(X8^2)*X13+(X10+X11)*X13+I((X8+X11)^3)*X15+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X13+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X15+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X14+(X1+X2+X3+X4+X5+X6+X7+X9+X12)*X16
lm26 <- Analisis_lm_fold(modelo26,nombre)
#lm26
dflm <- data.frame(rbind(model1=lm1,model2=lm2,model3=lm3,model4=lm4,model5=lm5,model6=lm6,
model7=lm7,model8=lm8,model9=lm9,model10=lm10,model11=lm11,model12=lm12,model13=lm13
,model14=lm14,model15=lm15,model16=lm16,model17=lm17,model18=lm18,model19=lm19,model20=lm20
,model21=lm21,model22=lm22,model23=lm23,model24=lm24,model25=lm25,model26=lm26))
dflm
dflm[which.min(as.numeric(dflm[,8])),]
##El modelo que ha obtenido un menor MSE en test ha sido el modelo 20
##Vemos que su R2 de 0,747 y un R2adj de 0,742 por lo que se explica un 74% del problema
dflm[which.min(as.numeric(dflm[,7])),]
##El modelo 16 tiene el menor MSE en train
##Este modelo tiene muy buen R2
dflm[which.max(as.numeric(dflm[,7])),]
##El modelo con un mayor MSE en training es el modelo 19
dflm[which.max(as.numeric(dflm[,8])),]
##El modelo 17 obtiene el mayor MSE en test, por lo que indica sobre-ajuste del modelo.
dflm[which.max(as.numeric(dflm[,3])),]
##El modelo 16 ha obtenido el mayor R2
dflm[which.max(as.numeric(dflm[,5])),]
##Siendo el mismo que ha obtenido el R2adj mayor.
dflm[16:20,]
##Por lo tanto tenemos para elegir entre dos modelos el 16 o el 20.
##Como mejor modelo para esta parte eligiría el modelo 20 al tener un menor MSEtest,
##pero se decidirá más adelante al comparar con knn
dflm[c(16,20),]
summary(fitM20)
modelo20
modelo22
set.seed(1234)
##Si realizamos un análisis como el de las transparencias, antes de aplicar knn-fold:
##Modelo para Runs
fitRunsknn=kknn(Salary~Runs,baseball,baseball)
##Modelo para Hits
fitHitsknn=kknn(Salary~Hits,baseball,baseball)
library(kknn)
set.seed(1234)
library(kknn)
##Si realizamos un análisis como el de las transparencias, antes de aplicar knn-fold:
##Modelo para Runs
fitRunsknn=kknn(Salary~Runs,baseball,baseball)
##Modelo para Hits
fitHitsknn=kknn(Salary~Hits,baseball,baseball)
##Modelo para Dobules
fitDoublesknn=kknn(Salary~Doubles,baseball,baseball)
##Modelo para HomeRuns
fitHomeRunsknn=kknn(Salary~HomeRuns,baseball,baseball)
##Modelo para Runs_batted_in
fitRunsBattedInknn=kknn(Salary~Runs_batted_in,baseball,baseball)
par(mfrow=c(3,2))
plot(Salary~Runs)
points(Runs,fitRunsknn$fitted.values,col="red",pch=20)
plot(Salary~Hits)
points(Hits,fitHitsknn$fitted.values,col="green",pch=20)
plot(Salary~Doubles)
points(Doubles,fitDoublesknn$fitted.values,col="blue",pch=20)
plot(Salary~HomeRuns)
points(HomeRuns,fitHomeRunsknn$fitted.values,col="orange",pch=20)
plot(Salary~Runs_batted_in)
points(Runs_batted_in,fitRunsBattedInknn$fitted.values,col="brown",pch=20)
par(mfrow=c(1,1))
yprime=fitRunsknn$fitted.values
rmse_runs <- sqrt(sum((Salary-yprime)^2)/length(yprime))
yprime=fitHitsknn$fitted.values
rmse_hits <- sqrt(sum((Salary-yprime)^2)/length(yprime))
yprime=fitDoublesknn$fitted.values
rmse_doubles <- sqrt(sum((Salary-yprime)^2)/length(yprime))
yprime=fitHomeRunsknn$fitted.values
rmse_home_runs <- sqrt(sum((Salary-yprime)^2)/length(yprime))
yprime=fitRunsBattedInknn$fitted.values
rmse_runs_batted_in <- sqrt(sum((Salary-yprime)^2)/length(yprime))
mat_rmse_knn <- matrix(c(rmse_runs,rmse_hits,rmse_doubles,rmse_home_runs,rmse_runs_batted_in))
colnames(mat_rmse_knn) <- c("RMSEknn")
##Uno los matrices y la muestro
regresion_simple_knn <- cbind(regresion_simple,mat_rmse_knn)
regresion_simple_knn
#Viendo que el RMSEknn es menor que el de lm
##Función para realizar cross-validation de los modelos knn
run_knn_fold <- function(i, x,modelo, tt = "test") {
file <- paste(x, "-5-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@")
file <- paste(x, "-5-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@")
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
if (tt == "train") {
test <- x_tra
}
else {
test <- x_tst
}
fitMulti=kknn(modelo,x_tra,test)
yprime=fitMulti$fitted.values
rmse <- sqrt(sum((test$Y-yprime)^2)/length(yprime))
mse <- sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
salida <- list("MSE"=mse, "RMSE"=rmse)
return (salida)
}
##Función para realizar el análisis de cross-validation
Analisis_knn_fold <- function(modelo, nombre){
knnMSEtrain<-(sapply(1:5,run_knn_fold,nombre,modelo,"train"))
knnMSEtest<-(sapply(1:5,run_knn_fold,nombre,modelo,"test"))
a <- mean(as.numeric(knnMSEtest[2,]))
salida <- list ( "MSEtrain" = mean(as.numeric(knnMSEtrain[1,])),
"MSEtest" = mean(as.numeric(knnMSEtest[1,])),
"RMSE"=a)
return (salida)
}
set.seed(1234)
knn1 <- Analisis_knn_fold(modelo1,nombre)
knn2 <- Analisis_knn_fold(modelo2,nombre)
knn3 <- Analisis_knn_fold(modelo3,nombre)
knn4 <- Analisis_knn_fold(modelo4,nombre)
knn5 <- Analisis_knn_fold(modelo5,nombre)
knn6 <- Analisis_knn_fold(modelo6,nombre)
knn7 <- Analisis_knn_fold(modelo7,nombre)
knn8 <- Analisis_knn_fold(modelo8,nombre)
knn9 <- Analisis_knn_fold(modelo9,nombre)
knn10 <- Analisis_knn_fold(modelo10,nombre)
knn11 <- Analisis_knn_fold(modelo11,nombre)
knn12 <- Analisis_knn_fold(modelo12,nombre)
knn13 <- Analisis_knn_fold(modelo13,nombre)
knn14 <- Analisis_knn_fold(modelo14,nombre)
knn15 <- Analisis_knn_fold(modelo15,nombre)
knn16 <- Analisis_knn_fold(modelo16,nombre)
knn17 <- Analisis_knn_fold(modelo17,nombre)
knn18 <- Analisis_knn_fold(modelo18,nombre)
knn19 <- Analisis_knn_fold(modelo19,nombre)
knn20 <- Analisis_knn_fold(modelo20,nombre)
knn21 <- Analisis_knn_fold(modelo21,nombre)
knn22 <- Analisis_knn_fold(modelo22,nombre)
knn23 <- Analisis_knn_fold(modelo23,nombre)
knn24 <- Analisis_knn_fold(modelo24,nombre)
knn25 <- Analisis_knn_fold(modelo25,nombre)
knn26 <- Analisis_knn_fold(modelo26,nombre)
knn1
dfknn <- data.frame(rbind(model1=knn1,model2=knn2,model3=knn3,model4=knn4,model5=knn5,model6=knn6,
model7=knn7,model8=knn8,model9=knn9,model10=knn10,model11=knn11,model12=knn12,model13=knn13
,model14=knn14,model15=knn15,model16=knn16,model17=knn17,model18=knn18,model19=knn19,model20=knn20
,model21=knn21,model22=knn22,model23=knn23,model24=knn24,model25=knn25,model26=knn26))
dfknn
##Buscamos el que menor MSE en test tenga:
dfknn[which.min(as.numeric(dfknn[,2])),]
##Que es el modelo 22
##El que menor MSE en train tiene es:
dfknn[which.min(as.numeric(dfknn[,1])),]
##El modelo 25
##El que mayor MSE en test presenta es:
dfknn[which.max(as.numeric(dfknn[,2])),]
##El modelo 3
##Y el que mayor MSE en train tiene es:
dfknn[which.max(as.numeric(dfknn[,1])),]
##También el modelo 3
dfknn[c(22,25),]
##Por lo tanto tenemos que los modelos 22 y 25 presentan MSE bajos para test o train,
##y como no coincide con ninguno de los mejores modelo que dieron en lm, para esta parte
##creo que el mejormodelo sería el modelo 22 al tener un MSE de test menor
modelo22
##Si queremos quedarnos con el mejor modelo de entre knn y lm tenemos que:
dflm[20,]
dfknn[22,]
##Si comparamos por MSEtest tenemos que:
dflm[20,8]
dfknn[22,2]
##El modelo 20 tiene un menor valor de MSEtest
##Si observamos el de train:
dflm[20,7]
dfknn[22,1]
##El modelo 22 tiene un menor valor de MSEtrain
##Para la comparativa final me decantaré final me quedaré con el modelo 20 por tener
##un valor de MSEtest más pequeño
###############################################################
############### COMPARACIÓN DE ALGORITMOS #####################
###############################################################
##Comparativa general entre distintos algoritmos
##leemos la tabla con los errores medios de test
resultados <- read.csv("regr_test_alumnos.csv")
tablatst <- cbind(resultados[,2:dim(resultados)[2]])
colnames(tablatst) <- names(resultados)[2:dim(resultados)[2]]
rownames(tablatst) <- resultados[,1]
##leemos la tabla con los errores medios de test
resultados <- read.csv("regr_train_alumnos.csv")
tablatra <- cbind(resultados[,2:dim(resultados)[2]])
colnames(tablatra) <- names(resultados)[2:dim(resultados)[2]]
rownames(tablatra) <- resultados[,1]
tablatst["baseball",1] <- as.numeric(dflm[20,8])
tablatst["baseball",2] <- as.numeric(dfknn[20,2])
tablatst["baseball",]
tablatra["baseball",1] <- as.numeric(dflm[20,7])
tablatra["baseball",2] <- as.numeric(dfknn[20,1])
tablatra["baseball",]
##Comparativa por pares de LM y KNN para test (Wilcoxon´s test)
##lm (other) vs knn (ref)
## + 0.1 porque wilcox R falla para valores == 0 en la tabla
difs <- (tablatst[,1] - tablatst[,2]) / tablatst[,1]
wilc_1_2 <- cbind(ifelse (difs<0, abs(difs)+0.1, 0+0.1), ifelse (difs>0, abs(difs)+0.1, 0+0.1))
colnames(wilc_1_2) <- c(colnames(tablatst)[1], colnames(tablatst)[2])
head(wilc_1_2)
##Se aplica el test Wilcoxon para interpretar los resultados
LMvsKNNtst <- wilcox.test(wilc_1_2[,1], wilc_1_2[,2], alternative = "two.sided", paired=TRUE)
Rmas <- LMvsKNNtst$statistic
pvalue <- LMvsKNNtst$p.value
LMvsKNNtst <- wilcox.test(wilc_1_2[,2], wilc_1_2[,1], alternative = "two.sided", paired=TRUE)
Rmenos <- LMvsKNNtst$statistic
Rmas
Rmenos
pvalue
##Comparativa por pares de LM y KNN para train (Wilcoxon´s test)
##lm (other) vs knn (ref)
## + 0.1 porque wilcox R falla para valores == 0 en la tabla
difs <- (tablatra[,1] - tablatra[,2]) / tablatra[,1]
wilc_1_2 <- cbind(ifelse (difs<0, abs(difs)+0.1, 0+0.1), ifelse (difs>0, abs(difs)+0.1, 0+0.1))
colnames(wilc_1_2) <- c(colnames(tablatra)[1], colnames(tablatra)[2])
head(wilc_1_2)
##Se aplica el test Wilcoxon para interpretar los resultados
LMvsKNNtst <- wilcox.test(wilc_1_2[,1], wilc_1_2[,2], alternative = "two.sided", paired=TRUE)
Rmas <- LMvsKNNtst$statistic
pvalue <- LMvsKNNtst$p.value
LMvsKNNtst <- wilcox.test(wilc_1_2[,2], wilc_1_2[,1], alternative = "two.sided", paired=TRUE)
Rmenos <- LMvsKNNtst$statistic
Rmas
Rmenos
pvalue
##Comparativas múltiples con Friedman y post-hoc Holm
test_friedman <- friedman.test(as.matrix(tablatst))
test_friedman
##Existen diferencias significativas al menos entre un par de algoritmos ya que p-value es menor a 0.05
##Aplicamos post-hoc Holm
tam <- dim(tablatst)
groups <- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(tablatst), groups, p.adjust = "holm", paired = TRUE)
test_friedman
pairwise.wilcox.test(as.matrix(tablatst), groups, p.adjust = "holm", paired = TRUE)
test_friedman <- friedman.test(as.matrix(tablatra))
test_friedman
##Existen diferencias significativas al menos entre un par de algoritmos ya que p-value es menor a 0.05
##Aplicamos post-hoc Holm
tam <- dim(tablatra)
groups <- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(tablatra), groups, p.adjust = "holm", paired = TRUE)
