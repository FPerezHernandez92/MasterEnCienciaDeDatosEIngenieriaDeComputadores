# Ejemplo que ilustra el modelo de clasificación en base a 3 variables
model3 <- glm(y~ns(x2,16)+ns(x1,16)+ns(x3,16), data =datos)
c <- predict(model3, newdata = datos)
plantilla <-matrix(c(0,0,0,0),ncol=4)
for (p1 in seq(1,8,(8-1)/10))
for (p2 in seq(1,7,(7-1)/10))
for (p3 in seq(0, 2.5, 2.5/10 ))
plantilla <-rbind(plantilla, c(x1=p1,x2=p2,x3=p3,y=0))
plantilla <- as.data.frame(plantilla)
plantilla[,4] <- round(predict(model3, newdata = plantilla))
plantilla[,4] <- ifelse(plantilla[,4]<1,"white", ifelse(plantilla[,4]>3,"white",plantilla[,4]))
#saca la grafica en 3d
library(rgl)
rgl_init()
rgl.spheres(x=datos$x2, y=datos$x1, z=datos$x3, r=0.1, col=datos$y)
rgl_add_axes(x=datos$x2, y=datos$x1, z=datos$x3, show.bbox = T)
aspect3d(1,1,1)
#### Ilustra como se distribuyen los espacios de clasificación
rgl_init()
rgl.spheres(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], r=0.1, col=plantilla[,4])
#rgl_add_axes(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], show.bbox = T)
aspect3d(1,1,1)
plot3d(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], col=plantilla[,4])
rgl_init()
rgl.spheres(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], r=0.1, col=plantilla[,4])
rgl_add_axes(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], show.bbox = T)
aspect3d(1,1,1)
plot3d(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], col=plantilla[,4])
library(tree)
summary(iris)
# Construir un arbol que clasifica la especie en base al resto de variables
tree.iris = tree(Species~.,iris)
library(tree)
install.packages("tree")
summary(iris)
# Construir un arbol que clasifica la especie en base al resto de variables
tree.iris = tree(Species~.,iris)
library(tree)
summary(iris)
# Construir un arbol que clasifica la especie en base al resto de variables
tree.iris = tree(Species~.,iris)
summary(tree.iris)
plot(tree.iris)
text(tree.iris, pretty=0)
tree.iris
# Dividir en training y test
set.seed (2)
train=sample (1:nrow(iris), 100)
iris.test=iris [-train ,]
# Construyo el arbol sobre el conjunto de entrenamiento
tree.iris =tree(Species~. ,iris ,subset =train )
# Aplico el arbol sobre el conjunto de test
tree.pred =predict (tree.iris ,iris.test ,type ="class")
# Visualizo la matriz de confusion
table(tree.pred , iris.test[,5])
# Podar el arbol usando cv
set.seed (3)
cv.iris = cv.tree(tree.iris ,FUN=prune.misclass )
names(cv.iris )
cv.iris
# Pintamos el error
par(mfrow =c(1,2))
plot(cv.iris$size ,cv.iris$dev ,type="b")
plot(cv.iris$k ,cv.iris$dev ,type="b")
# Ahora podamos el arbol con prune.misclass
prune.iris =prune.misclass (tree.iris ,best =3)
par(mfrow =c(1,1))
plot(prune.iris)
text(prune.iris ,pretty =0)
# Como se comportara este arbol en su capacidad de prediccion
tree.pred=predict (prune.iris , iris.test ,type="class")
table(tree.pred ,iris.test[,5])
# Ahora podemos modificar el tamanio del arbol modificando best
prune.iris =prune.misclass (tree.iris ,best =4)
plot(prune.iris)
text(prune.iris ,pretty =0)
tree.pred=predict (prune.iris , iris.test ,type="class")
table(tree.pred ,iris.test[,5])
# Random Forest
library (randomForest)
set.seed (1)
bag.iris = randomForest(Species~., data=iris, subset=train)
bag.iris
yhat.bag = predict (bag.iris ,newdata =iris.test)
yhat.bag
# Construyo una funcion para calcular el acierto a partir del RandomForest
acierto <- function(bag.datos){
return (sum (sapply(1:length(bag.datos$y), function(x){
if (is.na(bag.datos$predicted[x])){
0
}
else if (as.numeric(bag.datos$y[x])==as.numeric(bag.datos$predicted[x])){
1
}
else{
0
}
}))/length(bag.datos$y))
}
resul = as.data.frame(cbind(predicted = yhat.bag, y=iris.test[,5]))
acierto(resul)
# Fijando el numero de arboles
bag.iris = randomForest(Species~.,data=iris ,subset =train , ntree=25)
bag.iris
acierto(bag.iris)
bag.func = randomForest(formula,data=datos,ntree=num_trees)
bag.func = randomForest(formula,data=datos,subset=train,ntree=num_trees)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
bag.func = randomForest(formula,data=datos,subset=train,ntree=num_trees)
acierto(bag.func)
}
Graphical_RF(iris,Species~.,100)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
}
Graphical_RF(iris,Species~.,100)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
}
Graphical_RF(iris,Species~.,100)
vec
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
vec
}
Graphical_RF(iris,Species~.,100)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
plot(1:num_trees,vec)
}
Graphical_RF(iris,Species~.,100)
lines()
lines(vec)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
plot(1:num_trees,vec)
lines(vec)
}
Graphical_RF(iris,Species~.,100)
summary(iris)
summary(Auto)
Auto
Autos
summary(Autos)
library(ISLR)
summary(Autos)
summary(Auto)
dim(Auto)
dim(iris)
set.seed (2)
train=sample (1:nrow(Auto), 300)
datos = Auto
Graphical_RF(datos,origin~.-name,100)
train=sample (1:nrow(iris), 100)
set.seed (2)
train=sample (1:nrow(iris), 100)
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/1 Introduccion a la Ciencia de Datos/5 Trabajo Final/TrabajoFinal.R', echo=TRUE)
glmFit = glm(V15~.,data=australian_new,family=binomial)
summary(glmFit)
cor(australian_new[,1:7])
cor(australian_new[,1:6])
cor(australian_new[,1:6])[3,4]
run_metodo_fold <- function(i, x,metodo = "knn", tt="test",modelo=0){
file <- paste(x, "-10-", i, "tra.dat", sep="")
x_tra <- read.csv(file, comment.char="@")
In <- length(names(x_tra)) - 1
names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
names(x_tra)[In+1] <- "Y"
x_tra <- data.frame(lapply(x_tra, normalize))
x_tra$Y <- factor(x_tra$Y, levels = c(0, 1),labels = c("0", "1"))
file <- paste(x, "-10-", i, "tst.dat", sep="")
x_tst <- read.csv(file, comment.char="@")
names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
names(x_tst)[In+1] <- "Y"
x_tst <- data.frame(lapply(x_tst, normalize))
x_tst$Y <- factor(x_tst$Y, levels = c(0, 1), labels = c("0", "1"))
ultimo = 15
if (modelo == 1){
x_tra[,9] = x_tra[,9]*x_tra[,10]
x_tra[,10]=NULL
x_tst[,9] = x_tst[,9]*x_tst[,10]
x_tst[,10]=NULL
ultimo = 14
}
if (modelo == 2){
x_tra[,9] = x_tra[,9]*x_tra[,10]
x_tra[,10]=NULL
x_tst[,9] = x_tst[,9]*x_tst[,10]
x_tst[,10]=NULL
x_tra[,5] = x_tra[,5]*x_tra[,6]
x_tra[,6]=NULL
x_tst[,5] = x_tst[,5]*x_tst[,6]
x_tst[,6]=NULL
ultimo = 13
}
if (modelo == 3){
x_tra[,9] = x_tra[,9]*x_tra[,10]
x_tra[,10]=NULL
x_tst[,9] = x_tst[,9]*x_tst[,10]
x_tst[,10]=NULL
x_tra[,5] = x_tra[,5]*x_tra[,6]
x_tra[,6]=NULL
x_tst[,5] = x_tst[,5]*x_tst[,6]
x_tst[,6]=NULL
x_tra[,3]=NULL
x_tst[,3]=NULL
x_tra[,1]=NULL
x_tst[,1]=NULL
ultimo = 11
}
if (modelo == 4){
x_tra[,12]=NULL
x_tst[,12]=NULL
x_tra[,11]=NULL
x_tst[,11]=NULL
x_tra[,9] = x_tra[,9]*x_tra[,10]
x_tra[,10]=NULL
x_tst[,9] = x_tst[,9]*x_tst[,10]
x_tst[,10]=NULL
x_tra[,5] = x_tra[,5]*x_tra[,6]
x_tra[,6]=NULL
x_tst[,5] = x_tst[,5]*x_tst[,6]
x_tst[,6]=NULL
x_tra[,3]=NULL
x_tst[,3]=NULL
x_tra[,2]=NULL
x_tst[,2]=NULL
x_tra[,1]=NULL
x_tst[,1]=NULL
ultimo = 8
}
if (modelo == 5){
x_tra[,12]=NULL
x_tst[,12]=NULL
x_tra[,11]=NULL
x_tst[,11]=NULL
x_tra[,9] = x_tra[,9]*x_tra[,10]
x_tra[,10]=NULL
x_tst[,9] = x_tst[,9]*x_tst[,10]
x_tst[,10]=NULL
x_tra[,8] = x_tra[,8]*x_tra[,9]
x_tra[,9] = NULL
x_tst[,8] = x_tst[,8]*x_tst[,9]
x_tst[,9] = NULL
x_tra[,5] = x_tra[,5]*x_tra[,6]
x_tra[,6]=NULL
x_tst[,5] = x_tst[,5]*x_tst[,6]
x_tst[,6]=NULL
x_tra[,3]=NULL
x_tst[,3]=NULL
x_tra[,2]=NULL
x_tst[,2]=NULL
x_tra[,1]=NULL
x_tst[,1]=NULL
ultimo = 8
}
if (tt == "test"){
test_labels <- x_tst[,ultimo]
test <- x_tst[,-ultimo]
}
else {
test_labels <- x_tra[,ultimo]
test <- x_tra[,-ultimo]
}
train_labels <- x_tra[,ultimo]
aplicar_metodo_fold(x_tra[,-ultimo],train_labels,test,test_labels,metodo)
}
##Una vez creadas las funciones, realizo los cálculos
modelo_actual=5
set.seed(1234)
accuracy_train <- data.frame(sapply(1:10, run_metodo_fold, nombre, "knn", "train",modelo_actual))
mean_accuracy_train <- sum(accuracy_train[1,])/ncol(accuracy_train)
mean_accuracy_train #
set.seed(1234)
accuracy_test <- data.frame(sapply(1:10, run_metodo_fold, nombre, "knn", "test",modelo_actual))
mean_accuracy_test <- sum(accuracy_test[1,])/ncol(accuracy_test)
mean_accuracy_test #
mat_knn_val <- matrix(c(mean_accuracy_train,mean_accuracy_test))
rownames(mat_knn_val) <- c("Train","Test")
colnames(mat_knn_val) <- c("knn5")
set.seed(1234)
accuracy_train <- data.frame(sapply(1:10, run_metodo_fold, nombre,"glm", "train",modelo_actual))
mean_accuracy_train <- sum(accuracy_train)/nrow(accuracy_train)
mean_accuracy_train #
set.seed(1234)
accuracy_test <- data.frame(sapply(1:10, run_metodo_fold, nombre,"glm", "test",modelo_actual))
mean_accuracy_test <- sum(accuracy_test)/nrow(accuracy_test)
mean_accuracy_test #
mat_glm_val <- matrix(c(mean_accuracy_train,mean_accuracy_test))
rownames(mat_glm_val) <- c("Train","Test")
colnames(mat_glm_val) <- c("glm5")
set.seed(1234)
accuracy_train <- data.frame(sapply(1:10, run_metodo_fold, nombre, "lda", "train",modelo_actual))
mean_accuracy_train <- sum(accuracy_train)/nrow(accuracy_train)
mean_accuracy_train #
set.seed(1234)
accuracy_test <- data.frame(sapply(1:10, run_metodo_fold, nombre, "lda", "test",modelo_actual))
mean_accuracy_test <- sum(accuracy_test)/nrow(accuracy_test)
mean_accuracy_test #
mat_lda_val <- matrix(c(mean_accuracy_train,mean_accuracy_test))
rownames(mat_lda_val) <- c("Train","Test")
colnames(mat_lda_val) <- c("lda5")
set.seed(1234)
accuracy_train <- data.frame(sapply(1:10, run_metodo_fold, nombre, "qda", "train",modelo_actual))
mean_accuracy_train <- sum(accuracy_train)/nrow(accuracy_train)
mean_accuracy_train #
set.seed(1234)
accuracy_test <- data.frame(sapply(1:10, run_metodo_fold, nombre, "qda", "test",modelo_actual))
mean_accuracy_test <- sum(accuracy_test)/nrow(accuracy_test)
mean_accuracy_test#
mat_qda_val <- matrix(c(mean_accuracy_train,mean_accuracy_test))
rownames(mat_qda_val) <- c("Train","Test")
colnames(mat_qda_val) <- c("qda5")
resultados_clasificacion5 <- cbind(mat_knn_val,mat_glm_val,mat_lda_val,mat_qda_val)
resultados_clasificacion <- cbind(resultados_clasificacion0,resultados_clasificacion1,resultados_clasificacion2,resultados_clasificacion3,resultados_clasificacion4,resultados_clasificacion5)
resultados_clasificacion
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/1 Introduccion a la Ciencia de Datos/5 Trabajo Final/TrabajoFinal.R', echo=TRUE)
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/1 Introduccion a la Ciencia de Datos/5 Trabajo Final/TrabajoFinal.R', echo=TRUE)
dfknn
data_result_clasif <- as.data.frame(resultados_clasificacion)
data_result_clasif
data_result_clasif[which.min(as.numeric(data_result_clasif[,2]))]
data_result_clasif[which.max(as.numeric(data_result_clasif[,2]))]
View(data_result_clasif)
data_result_clasif[which.max(as.numeric(data_result_clasif[,]))]
data_result_clasif[,2]
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
data_result_clasif[2,]
data_result_clasif1 <- (data_result_clasif$knn4=NULL)
data_result_clasif
data_result_clasif$knn4=NULL
data_result_clasif
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
data_result_clasif$knn=NULL
data_result_clasif$knn1=NULL
data_result_clasif$knn2=NULL
data_result_clasif$knn3=NULL
data_result_clasif$knn5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
data_result_clasif <- as.data.frame(resultados_clasificacion)
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
##Donde vemos que el modelo con mayor Accuracy en test es el modelo 4, con knn
data_result_clasif$knn=NULL;data_result_clasif$knn1=NULL;data_result_clasif$knn2=NULL;data_result_clasif$knn3=NULL;data_result_clasif$knn4=NULL;data_result_clasif$knn5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
data_result_clasif$lda=NULL;data_result_clasif$lda1=NULL;data_result_clasif$lda2=NULL;
data_result_clasif$lda=NULL;data_result_clasif$lda1=NULL;data_result_clasif$lda2=NULL;data_result_clasif$lda3=NULL;data_result_clasif$lda4=NULL;data_result_clasif$lda5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
data_result_clasif$glm=NULL;data_result_clasif$glm1=NULL;data_result_clasif$glm2=NULL;data_result_clasif$glm3=NULL;
data_result_clasif$glm=NULL;data_result_clasif$glm1=NULL;data_result_clasif$glm2=NULL;data_result_clasif$glm3=NULL;data_result_clasif$glm4=NULL;data_result_clasif$glm5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
resultados_test <- read.csv("clasif_test_alumos.csv")
tablatst <- cbind(resultados_test[,2:dim(resultados_test)[2]])
tablatst
colnames(tablatst) <- names(resultados_test)[2:dim(resultados_test)[2]]
rownames(tablatst) <- resultados_test[,1]
resultados_test[16,]
resultados_test
resultados_test[2,]
resultados_train <- read.csv("clasif_train_alumnos.csv")
tablatra <- cbind(resultados_train[,2:dim(resultados_train)[2]])
colnames(tablatra) <- names(resultados_train)[2:dim(resultados_train)[2]]
rownames(tablatra) <- resultados_train[,1]
resultados_train[2,]
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))][,1]
mejor_knn_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[,1]
(data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[,1]
mejor_knn_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[1,]
mejor_knn_train
mejor_knn_test <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[2,]
mejor_knn_test
mejor_lda_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[1,]
mejor_lda_test <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[2,]
mejor_qda_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[1,]
mejor_qda_test <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[2,]
resultados_test
tablatst
tablatst[2,][1] <- mejor_knn_test
tablatst[2,][1] <- mejor_knn_test
tablatst[2,][2] <- mejor_lda_test
tablatst[2,][3] <- mejor_qda_test
tablatst[2,]
tablatra[2,][1] <- mejor_knn_train
tablatra[2,][2] <- mejor_lda_train
tablatra[2,][3] <- mejor_qda_train
tablatra[2,]
mejor_knn_test
data_result_clasif
data_result_clasif <- as.data.frame(resultados_clasificacion)
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
mejor_knn_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[1,]
mejor_knn_test <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[2,]
##Donde vemos que el modelo con mayor Accuracy en test es el modelo 4, con knn
data_result_clasif$knn=NULL;data_result_clasif$knn1=NULL;data_result_clasif$knn2=NULL;data_result_clasif$knn3=NULL;data_result_clasif$knn4=NULL;data_result_clasif$knn5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
mejor_lda_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[1,]
mejor_lda_test <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[2,]
##El segundo mejor modelo, sin knn, es el modelo 1 para lda
data_result_clasif$lda=NULL;data_result_clasif$lda1=NULL;data_result_clasif$lda2=NULL;data_result_clasif$lda3=NULL;data_result_clasif$lda4=NULL;data_result_clasif$lda5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
##Para glm vemos como el mejor modelo es el modelo 4
data_result_clasif$glm=NULL;data_result_clasif$glm1=NULL;data_result_clasif$glm2=NULL;data_result_clasif$glm3=NULL;data_result_clasif$glm4=NULL;data_result_clasif$glm5=NULL
data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))]
mejor_qda_train <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[1,]
mejor_qda_test <- (data_result_clasif[which.max(as.numeric(data_result_clasif[2,]))])[2,]
##Por último, para qda, el mejor modelo es el modelo 5
##Por lo que, nuestro mejor modelo ha sido el modelo 4 en el que hacimos la unión de las variables V10 con V9 y V5 con V6, y eliminabamos
##las variables V12, V11, V3, V2 y V1, usando knn
###############################################################
######################### COMPARACIÓN #########################
###############################################################
##leemos la tabla con los errores medios de test
resultados_test <- read.csv("clasif_test_alumos.csv")
tablatst <- cbind(resultados_test[,2:dim(resultados_test)[2]])
colnames(tablatst) <- names(resultados_test)[2:dim(resultados_test)[2]]
rownames(tablatst) <- resultados_test[,1]
resultados_test[2,]
##leemos la tabla con los errores medios de train
resultados_train <- read.csv("clasif_train_alumnos.csv")
tablatra <- cbind(resultados_train[,2:dim(resultados_train)[2]])
colnames(tablatra) <- names(resultados_train)[2:dim(resultados_train)[2]]
rownames(tablatra) <- resultados_train[,1]
resultados_train[2,]
##Añadir los valores resultantes en test
tablatst[2,][1] <- mejor_knn_test
tablatst[2,][2] <- mejor_lda_test
tablatst[2,][3] <- mejor_qda_test
tablatst[2,]
##Añadir los valores resultantes en train
tablatra[2,][1] <- mejor_knn_train
tablatra[2,][2] <- mejor_lda_train
tablatra[2,][3] <- mejor_qda_train
tablatra[2,]
tablatra[2,]
resultados_test <- read.csv("clasif_test_alumos.csv")
tablatst <- cbind(resultados_test[,2:dim(resultados_test)[2]])
colnames(tablatst) <- names(resultados_test)[2:dim(resultados_test)[2]]
rownames(tablatst) <- resultados_test[,1]
resultados_test[2,]
##leemos la tabla con los errores medios de train
resultados_train <- read.csv("clasif_train_alumnos.csv")
tablatra <- cbind(resultados_train[,2:dim(resultados_train)[2]])
colnames(tablatra) <- names(resultados_train)[2:dim(resultados_train)[2]]
rownames(tablatra) <- resultados_train[,1]
resultados_train[2,]
##Añadir los valores resultantes en test
tablatst[2,][1] <- mejor_knn_test
tablatst[2,][2] <- mejor_lda_test
tablatst[2,][3] <- mejor_qda_test
tablatst[2,]
##Añadir los valores resultantes en train
tablatra[2,][1] <- mejor_knn_train
tablatra[2,][2] <- mejor_lda_train
tablatra[2,][3] <- mejor_qda_train
tablatra[2,]
difs <- (tablatst[,2] - tablatst[,3]) / tablatst[,2]
wilc_1_2 <- cbind(ifelse (difs<0, abs(difs)+0.1, 0+0.1), ifelse (difs>0, abs(difs)+0.1, 0+0.1))
colnames(wilc_1_2) <- c(colnames(tablatst)[2], colnames(tablatst)[3])
head(wilc_1_2)
LDAvsQDAtst <- wilcox.test(wilc_1_2[,2], wilc_1_2[,3], alternative = "two.sided", paired=TRUE)
LDAvsQDAtst <- wilcox.test(wilc_1_2[,1], wilc_1_2[,2], alternative = "two.sided", paired=TRUE)
Rmas <- LDAvsQDAtst$statistic
pvalue <- LDAvsQDAtst$p.value
LDAvsQDAtst <- wilcox.test(wilc_1_2[,2], wilc_1_2[,1], alternative = "two.sided", paired=TRUE)
Rmenos <- LDAvsQDAtst$statistic
Rmas
Rmenos
pvalue
difs <- (tablatra[,2] - tablatra[,3]) / tablatra[,2]
wilc_1_2 <- cbind(ifelse (difs<0, abs(difs)+0.1, 0+0.1), ifelse (difs>0, abs(difs)+0.1, 0+0.1))
colnames(wilc_1_2) <- c(colnames(tablatra)[2], colnames(tablatra)[3])
head(wilc_1_2)
LDAvsQDAtst <- wilcox.test(wilc_1_2[,1], wilc_1_2[,2], alternative = "two.sided", paired=TRUE)
Rmas <- LDAvsQDAtst$statistic
pvalue <- LDAvsQDAtst$p.value
LDAvsQDAtst <- wilcox.test(wilc_1_2[,2], wilc_1_2[,1], alternative = "two.sided", paired=TRUE)
Rmenos <- LDAvsQDAtst$statistic
Rmas
Rmenos
pvalue
tablatst
test_friedman <- friedman.test(as.matrix(tablatst))
test_friedman
tam <- dim(tablatst)
groups <- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(tablatst), groups, p.adjust = "holm", paired = TRUE)
test_friedman <- friedman.test(as.matrix(tablatra))
test_friedman
tam <- dim(tablatra)
groups <- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(tablatra), groups, p.adjust = "holm", paired = TRUE)
